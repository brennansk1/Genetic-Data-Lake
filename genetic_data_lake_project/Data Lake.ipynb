{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"_aoHqs1EXLeR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739387947804,"user_tz":420,"elapsed":21418,"user":{"displayName":"Brennan Kelley","userId":"17999519178876901974"}},"outputId":"96eecf2e-56b1-4b41-e750-5ec44e34dbbe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n","Collecting faker\n","  Downloading Faker-36.1.0-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (5.9.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Downloading Faker-36.1.0-py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: faker\n","Successfully installed faker-36.1.0\n"]}],"source":["!pip install pandas numpy faker tqdm psutil\n","\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Y5dsSBwEXDyn","executionInfo":{"status":"error","timestamp":1739388929369,"user_tz":420,"elapsed":977463,"user":{"displayName":"Brennan Kelley","userId":"17999519178876901974"}},"outputId":"2dc7f698-48e3-43ab-f029-7e5ef58f34a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generating individuals data in chunks...\n"]},{"output_type":"stream","name":"stderr","text":["Individuals Chunks: 100%|██████████| 10/10 [00:42<00:00,  4.26s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Individuals data saved to data_lake/individuals.csv\n","Generating family relationships...\n","Relationships data saved to data_lake/relationships.csv\n","Generating marriages data...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-2-4dbb6bbc396c>:243: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  paired[\"male_18\"] = paired[\"male_birth\"] + pd.to_timedelta(18*365, unit=\"D\")\n","<ipython-input-2-4dbb6bbc396c>:244: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  paired[\"female_18\"] = paired[\"female_birth\"] + pd.to_timedelta(18*365, unit=\"D\")\n","<ipython-input-2-4dbb6bbc396c>:245: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  paired[\"marriage_start\"] = paired[[\"male_18\", \"female_18\"]].max(axis=1)\n","<ipython-input-2-4dbb6bbc396c>:246: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  paired[\"marriage_end\"] = paired[[\"male_sample\", \"female_sample\"]].min(axis=1)\n","<ipython-input-2-4dbb6bbc396c>:251: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  paired[\"marriage_date\"] = vectorized_random_date(paired[\"marriage_start\"], paired[\"marriage_end\"])\n","<ipython-input-2-4dbb6bbc396c>:255: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  paired.loc[divorce_mask, \"divorce_date\"] = vectorized_random_date(divorce_start, pd.Series(divorce_end, index=divorce_start.index))\n"]},{"output_type":"stream","name":"stdout","text":["Marriages data saved to data_lake/marriages.csv\n","Generating SNP definitions with genomic annotations...\n"]},{"output_type":"stream","name":"stderr","text":["SNP Definitions: 100%|██████████| 1000/1000 [00:00<00:00, 64223.43it/s]"]},{"output_type":"stream","name":"stdout","text":["SNP definitions saved to data_lake/snp_definitions.csv\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Generating SNP genotypes for individuals (writing in chunks)...\n","Writing SNP genotypes in chunks...\n"]},{"output_type":"stream","name":"stderr","text":["SNP Genotype Chunks: 100%|██████████| 10/10 [10:51<00:00, 65.11s/it]\n"]},{"output_type":"stream","name":"stdout","text":["SNP genotype data saved to data_lake/snps.csv\n","Generating Indel definitions with genomic annotations...\n"]},{"output_type":"stream","name":"stderr","text":["Indel Definitions: 100%|██████████| 200/200 [00:00<00:00, 27791.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Indel definitions saved to data_lake/indel_definitions.csv\n","Writing indel genotypes in chunks...\n"]},{"output_type":"stream","name":"stderr","text":["Indel Genotype Chunks: 100%|██████████| 10/10 [02:57<00:00, 17.74s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Indel genotype data saved to data_lake/indels.csv\n","Generating structural variants data...\n"]},{"output_type":"stream","name":"stderr","text":["Structural Variants: 100%|██████████| 1000000/1000000 [01:11<00:00, 13917.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Structural variants data saved to data_lake/structural_variants.csv\n","Generating health and phenotype data (vectorized)...\n","Health and phenotype data saved to data_lake/health_phenotypes.csv\n","Generating lifestyle data (vectorized)...\n","Lifestyle data saved to data_lake/lifestyle.csv\n","All stages completed. Launching output summary UI...\n"]},{"output_type":"error","ename":"TclError","evalue":"no display name and no $DISPLAY environment variable","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-4dbb6bbc396c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All stages completed. Launching output summary UI...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m \u001b[0mshow_summary_ui\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_generated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-2-4dbb6bbc396c>\u001b[0m in \u001b[0;36mshow_summary_ui\u001b[0;34m(file_list)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;31m# =============================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshow_summary_ui\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m     \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data Generation Summary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"500x300\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2324\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2325\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2328\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"]}],"source":["import os\n","import random\n","import csv\n","import pandas as pd\n","import numpy as np\n","from faker import Faker\n","from datetime import datetime, timedelta\n","from tqdm import tqdm\n","import tkinter as tk\n","from tkinter import ttk\n","import gc\n","import psutil\n","import time\n","\n","# ---------------------------\n","# Helper Functions\n","# ---------------------------\n","def random_date_after(start_date, end_date):\n","    \"\"\"Return a random datetime between start_date and end_date.\"\"\"\n","    delta = (end_date - start_date).days\n","    random_days = np.random.randint(0, delta + 1)\n","    return start_date + timedelta(days=int(random_days))\n","\n","def get_random_chromosome():\n","    \"\"\"Randomly select a chromosome with realistic weighting.\n","       Autosomes (1-22) share 90% weight; X gets 8%, Y gets 1.5%, MT gets 0.5%.\"\"\"\n","    autosomes = [str(i) for i in range(1, 23)]\n","    others = [\"X\", \"Y\", \"MT\"]\n","    chromosomes = autosomes + others\n","    weights = [0.9/22]*22 + [0.08, 0.015, 0.005]\n","    return random.choices(chromosomes, weights=weights, k=1)[0]\n","\n","def get_functional_effect(region_type):\n","    \"\"\"Return a functional effect based on the genomic region type.\"\"\"\n","    if region_type == \"exonic\":\n","        return random.choices([\"synonymous\", \"nonsynonymous\", \"stop_gain\", \"stop_loss\"],\n","                              weights=[0.7, 0.25, 0.03, 0.02], k=1)[0]\n","    elif region_type in [\"promoter\", \"enhancer\"]:\n","        return \"regulatory\"\n","    elif region_type in [\"5' UTR\", \"3' UTR\"]:\n","        return \"untranslated\"\n","    else:\n","        return \"non-coding\"\n","\n","def check_memory(limit_percent=80):\n","    \"\"\"\n","    Pause processing if system memory usage exceeds limit_percent.\n","    (E.g. limit_percent=80 means pause if >80% memory is used.)\n","    \"\"\"\n","    while psutil.virtual_memory().percent > limit_percent:\n","        print(f\"Memory usage high: {psutil.virtual_memory().percent}% - waiting...\")\n","        time.sleep(1)\n","\n","# ---------------------------\n","# Global Parameters\n","# ---------------------------\n","NUM_INDIVIDUALS = 1_000_000    # For full-scale; for testing, you might use a lower number (e.g., 10_000)\n","NUM_SNPS = 1000              # Number of SNP markers\n","NUM_INDELS = 200             # Number of Indels\n","ANCESTRY_GROUPS = [\"North European\", \"Sub-Saharan African\", \"Native American\",\n","                   \"East Asian\", \"South Asian\", \"Middle Eastern\"]\n","SV_PROBABILITY = 0.05        # 5% of individuals have a structural variant record\n","\n","# Use a more memory-efficient float type\n","float_dtype = np.float32\n","\n","# Approximate chromosome lengths and region types\n","chr_lengths = {str(i): 150_000_000 for i in range(1, 23)}\n","chr_lengths.update({\"X\": 155_000_000, \"Y\": 60_000_000, \"MT\": 16_569})\n","region_types = [\"intergenic\", \"intronic\", \"exonic\", \"promoter\", \"5' UTR\", \"3' UTR\", \"enhancer\"]\n","region_weights = [0.5, 0.3, 0.1, 0.05, 0.02, 0.02, 0.01]\n","\n","# Memory threshold: pause if memory usage exceeds this percent\n","MEMORY_THRESHOLD_PERCENT = 80\n","\n","# ---------------------------\n","# Setup Output Directory and File Paths\n","# ---------------------------\n","output_dir = \"data_lake\"\n","os.makedirs(output_dir, exist_ok=True)\n","individuals_file = os.path.join(output_dir, \"individuals.csv\")\n","relationships_file = os.path.join(output_dir, \"relationships.csv\")\n","marriages_file = os.path.join(output_dir, \"marriages.csv\")\n","snp_def_file = os.path.join(output_dir, \"snp_definitions.csv\")\n","snp_file = os.path.join(output_dir, \"snps.csv\")\n","indel_def_file = os.path.join(output_dir, \"indel_definitions.csv\")\n","indel_file = os.path.join(output_dir, \"indels.csv\")\n","sv_file = os.path.join(output_dir, \"structural_variants.csv\")\n","health_file = os.path.join(output_dir, \"health_phenotypes.csv\")\n","lifestyle_file = os.path.join(output_dir, \"lifestyle.csv\")\n","\n","# Initialize Faker\n","fake = Faker()\n","\n","# =============================================================================\n","# Step 1: Generate Individuals Data in Chunks\n","# =============================================================================\n","def generate_individuals_chunk(start_idx, chunk_size, total):\n","    \"\"\"Generate a chunk of individuals data and return a DataFrame.\"\"\"\n","    n = chunk_size if start_idx + chunk_size <= total else total - start_idx\n","    ids = [f\"ID_{i+1:07d}\" for i in range(start_idx, start_idx+n)]\n","    genders = np.random.choice([\"Male\", \"Female\"], size=n)\n","    # Generate fixed pools per chunk for consistency\n","    male_first_pool = [fake.first_name_male() for _ in range(1000)]\n","    female_first_pool = [fake.first_name_female() for _ in range(1000)]\n","    last_pool = [fake.last_name() for _ in range(1000)]\n","    country_pool = [fake.country() for _ in range(500)]\n","    city_pool = [fake.city() for _ in range(500)]\n","    state_pool = [fake.state() for _ in range(500)]\n","    lat_pool = [float(fake.latitude()) for _ in range(500)]\n","    lon_pool = [float(fake.longitude()) for _ in range(500)]\n","\n","    first_names = np.where(genders == \"Male\",\n","                           np.random.choice(male_first_pool, size=n),\n","                           np.random.choice(female_first_pool, size=n))\n","    last_names = np.random.choice(last_pool, size=n)\n","    countries = np.random.choice(country_pool, size=n)\n","    cities = np.random.choice(city_pool, size=n)\n","    states = np.random.choice(state_pool, size=n)\n","    latitudes = np.random.choice(lat_pool, size=n)\n","    longitudes = np.random.choice(lon_pool, size=n)\n","\n","    start_birth = pd.Timestamp(\"1920-01-01\")\n","    end_birth = pd.Timestamp(\"2010-12-31\")\n","    birth_days = np.random.randint(0, (end_birth - start_birth).days + 1, size=n)\n","    birth_dates = start_birth + pd.to_timedelta(birth_days, unit=\"D\")\n","    birth_dates_str = birth_dates.strftime(\"%Y-%m-%d\")\n","\n","    min_sample_dates = birth_dates + pd.to_timedelta(18*365, unit=\"D\")\n","    max_sample_date = pd.Timestamp(\"2022-12-31\")\n","    available_days = np.clip((max_sample_date - min_sample_dates).days, a_min=1, a_max=None)\n","    sample_offsets = np.array([np.random.randint(0, avail + 1) for avail in available_days])\n","    sample_collection_dates = min_sample_dates + pd.to_timedelta(sample_offsets, unit=\"D\")\n","    sample_collection_dates_str = sample_collection_dates.strftime(\"%Y-%m-%d\")\n","\n","    processing_offsets = np.random.randint(7, 31, size=n)\n","    processing_dates = sample_collection_dates + pd.to_timedelta(processing_offsets, unit=\"D\")\n","    processing_dates_str = processing_dates.strftime(\"%Y-%m-%d\")\n","\n","    coverage = np.maximum(5, np.random.normal(30, 5, n)).astype(float_dtype)\n","    coverage = np.round(coverage, 1)\n","    consent = np.random.choice([\"Yes\", \"No\"], size=n, p=[0.95, 0.05])\n","    ancestry = np.random.dirichlet(np.ones(len(ANCESTRY_GROUPS)), size=n) * 100\n","    ancestry = np.round(ancestry, 2)\n","    ancestry_df = pd.DataFrame(ancestry, columns=[g.replace(\" \", \"_\").lower() for g in ANCESTRY_GROUPS])\n","    batch_ids = [f\"BATCH_{random.randint(1,100):03d}\" for _ in range(n)]\n","\n","    df = pd.DataFrame({\n","        \"individual_id\": ids,\n","        \"first_name\": first_names,\n","        \"last_name\": last_names,\n","        \"gender\": genders,\n","        \"birth_date\": birth_dates_str,\n","        \"country\": countries,\n","        \"city\": cities,\n","        \"state\": states,\n","        \"latitude\": latitudes,\n","        \"longitude\": longitudes,\n","        \"sample_collection_date\": sample_collection_dates_str,\n","        \"processing_date\": processing_dates_str,\n","        \"coverage\": coverage,\n","        \"consent\": consent,\n","        \"batch_id\": batch_ids\n","    })\n","    df = pd.concat([df, ancestry_df], axis=1)\n","    df['birth_date_dt'] = pd.to_datetime(df['birth_date'])\n","    df['sample_collection_date_dt'] = pd.to_datetime(df['sample_collection_date'])\n","    return df\n","\n","print(\"Generating individuals data in chunks...\")\n","with open(individuals_file, \"w\", newline=\"\") as f_out:\n","    first_chunk = True\n","    for start in tqdm(range(0, NUM_INDIVIDUALS, 100000), desc=\"Individuals Chunks\"):\n","        check_memory(MEMORY_THRESHOLD_PERCENT)\n","        chunk_df = generate_individuals_chunk(start, 100000, NUM_INDIVIDUALS)\n","        if first_chunk:\n","            expected_cols = list(chunk_df.columns)\n","            chunk_df = chunk_df[expected_cols]\n","            chunk_df.to_csv(f_out, mode=\"w\", index=False, header=True)\n","            first_chunk = False\n","        else:\n","            chunk_df = chunk_df[expected_cols]\n","            chunk_df.to_csv(f_out, mode=\"a\", index=False, header=False)\n","        del chunk_df\n","        gc.collect()\n","print(f\"Individuals data saved to {individuals_file}\")\n","\n","# =============================================================================\n","# Step 2: Generate Family Relationships (Using np.searchsorted)\n","# =============================================================================\n","print(\"Generating family relationships...\")\n","individuals_df = pd.read_csv(individuals_file, parse_dates=[\"birth_date\", \"sample_collection_date\"])\n","individuals_df['birth_date_dt'] = pd.to_datetime(individuals_df['birth_date'])\n","individuals_df['sample_collection_date_dt'] = pd.to_datetime(individuals_df['sample_collection_date'])\n","individuals_df[\"gender\"] = individuals_df[\"gender\"].astype(\"category\")\n","individuals_df[\"consent\"] = individuals_df[\"consent\"].astype(\"category\")\n","children = individuals_df[[\"individual_id\", \"birth_date_dt\"]].copy().sort_values(\"birth_date_dt\")\n","child_thresholds = (children[\"birth_date_dt\"] - pd.DateOffset(years=20)).values.astype(\"datetime64[D]\")\n","eligible_fathers = individuals_df[individuals_df['gender'] == \"Male\"].copy().sort_values(\"birth_date_dt\")\n","father_births = eligible_fathers[\"birth_date_dt\"].values.astype(\"datetime64[D]\")\n","indices = np.searchsorted(father_births, child_thresholds)\n","father_ids = np.empty(len(indices), dtype=object)\n","mask = (indices == 0)\n","father_ids[~mask] = np.array(eligible_fathers[\"individual_id\"], dtype=object)[indices[~mask] - 1]\n","father_ids[mask] = None\n","eligible_mothers = individuals_df[individuals_df['gender'] == \"Female\"].copy().sort_values(\"birth_date_dt\")\n","mother_births = eligible_mothers[\"birth_date_dt\"].values.astype(\"datetime64[D]\")\n","indices_m = np.searchsorted(mother_births, child_thresholds)\n","mother_ids = np.empty(len(indices_m), dtype=object)\n","mask_m = (indices_m == 0)\n","mother_ids[~mask_m] = np.array(eligible_mothers[\"individual_id\"], dtype=object)[indices_m[~mask_m] - 1]\n","mother_ids[mask_m] = None\n","relationships_df = pd.DataFrame({\n","    \"individual_id\": children[\"individual_id\"],\n","    \"father_id\": father_ids,\n","    \"mother_id\": mother_ids\n","})\n","relationships_df.to_csv(relationships_file, index=False)\n","print(f\"Relationships data saved to {relationships_file}\")\n","del children, eligible_fathers, eligible_mothers, father_ids, mother_ids\n","gc.collect()\n","\n","# =============================================================================\n","# Step 3: Generate Marriages Data (Vectorized Pairing)\n","# =============================================================================\n","print(\"Generating marriages data...\")\n","individuals_df[\"age\"] = (individuals_df[\"sample_collection_date_dt\"] - individuals_df[\"birth_date_dt\"]).dt.days / 365.25\n","eligible = individuals_df[individuals_df[\"age\"] >= 18].copy()\n","males = eligible[eligible[\"gender\"] == \"Male\"].sample(frac=1, random_state=42).reset_index(drop=True)\n","females = eligible[eligible[\"gender\"] == \"Female\"].sample(frac=1, random_state=42).reset_index(drop=True)\n","min_len = min(len(males), len(females))\n","paired = pd.DataFrame({\n","    \"male_id\": males.loc[:min_len-1, \"individual_id\"].values,\n","    \"female_id\": females.loc[:min_len-1, \"individual_id\"].values,\n","    \"male_age\": males.loc[:min_len-1, \"age\"].values,\n","    \"female_age\": females.loc[:min_len-1, \"age\"].values,\n","    \"male_birth\": males.loc[:min_len-1, \"birth_date_dt\"].values,\n","    \"female_birth\": females.loc[:min_len-1, \"birth_date_dt\"].values,\n","    \"male_sample\": males.loc[:min_len-1, \"sample_collection_date_dt\"].values,\n","    \"female_sample\": females.loc[:min_len-1, \"sample_collection_date_dt\"].values,\n","})\n","paired = paired[np.abs(paired[\"male_age\"] - paired[\"female_age\"]) <= 10]\n","paired[\"male_18\"] = paired[\"male_birth\"] + pd.to_timedelta(18*365, unit=\"D\")\n","paired[\"female_18\"] = paired[\"female_birth\"] + pd.to_timedelta(18*365, unit=\"D\")\n","paired[\"marriage_start\"] = paired[[\"male_18\", \"female_18\"]].max(axis=1)\n","paired[\"marriage_end\"] = paired[[\"male_sample\", \"female_sample\"]].min(axis=1)\n","def vectorized_random_date(start_series, end_series):\n","    delta = (end_series - start_series).dt.days.clip(lower=0)\n","    random_days = (np.random.rand(len(delta)) * delta).astype(int)\n","    return start_series + pd.to_timedelta(random_days, unit=\"D\")\n","paired[\"marriage_date\"] = vectorized_random_date(paired[\"marriage_start\"], paired[\"marriage_end\"])\n","divorce_mask = np.random.rand(len(paired)) < 0.2\n","divorce_start = paired.loc[divorce_mask, \"marriage_date\"] + pd.to_timedelta(365, unit=\"D\")\n","divorce_end = pd.Timestamp(\"2022-12-31\")\n","paired.loc[divorce_mask, \"divorce_date\"] = vectorized_random_date(divorce_start, pd.Series(divorce_end, index=divorce_start.index))\n","marriages_df = paired[[\"male_id\", \"female_id\", \"marriage_date\", \"divorce_date\"]].copy()\n","marriages_df.to_csv(marriages_file, index=False)\n","print(f\"Marriages data saved to {marriages_file}\")\n","del paired, eligible, males, females\n","gc.collect()\n","\n","# =============================================================================\n","# Step 4: Generate SNP Definitions with Genomic Annotation\n","# =============================================================================\n","print(\"Generating SNP definitions with genomic annotations...\")\n","nucleotides = ['A', 'C', 'G', 'T']\n","snp_definitions = []\n","for i in tqdm(range(NUM_SNPS), desc=\"SNP Definitions\"):\n","    snp_id = f\"SNP_{i+1:04d}\"\n","    alleles = random.sample(nucleotides, 2)\n","    allele1_freq = random.uniform(0.1, 0.9)\n","    call_rate = round(random.uniform(0.95, 0.99), 3)\n","    quality_score = random.randint(20, 40)\n","    chromosome = get_random_chromosome()\n","    position = random.randint(1, chr_lengths[chromosome])\n","    region_type = random.choices(region_types, weights=region_weights, k=1)[0]\n","    functional_effect = get_functional_effect(region_type)\n","    snp_definitions.append({\n","        \"snp_id\": snp_id,\n","        \"allele1\": alleles[0],\n","        \"allele2\": alleles[1],\n","        \"allele1_freq\": round(allele1_freq, 3),\n","        \"call_rate\": call_rate,\n","        \"quality_score\": quality_score,\n","        \"chromosome\": chromosome,\n","        \"position\": position,\n","        \"region_type\": region_type,\n","        \"functional_effect\": functional_effect\n","    })\n","snp_def_df = pd.DataFrame(snp_definitions)\n","snp_def_df[\"chromosome\"] = snp_def_df[\"chromosome\"].astype(\"category\")\n","snp_def_df[\"region_type\"] = snp_def_df[\"region_type\"].astype(\"category\")\n","snp_def_df[\"functional_effect\"] = snp_def_df[\"functional_effect\"].astype(\"category\")\n","snp_def_df.to_csv(snp_def_file, index=False)\n","print(f\"SNP definitions saved to {snp_def_file}\")\n","del snp_definitions\n","gc.collect()\n","# For later use in SNP genotype generation, we will use the dictionary form:\n","snp_annotations = snp_def_df.to_dict('records')\n","\n","# =============================================================================\n","# Step 5: Generate SNP Genotypes (Chunked Writing to CSV, CPU Only)\n","# =============================================================================\n","print(\"Generating SNP genotypes for individuals (writing in chunks)...\")\n","# Helper function for genotype computation for one SNP marker for a chunk of individuals.\n","def compute_snp_genotype_for_chunk(snp_info, genders):\n","    \"\"\"Compute genotype calls for a given SNP marker for a chunk of individuals.\n","       genders: list-like of \"Male\" or \"Female\" for the individuals in this chunk.\"\"\"\n","    n = len(genders)\n","    genotypes = np.full(n, \"NA\", dtype=object)\n","    # Determine which individuals have a call based on call_rate\n","    call_mask = np.random.rand(n) <= snp_info[\"call_rate\"]\n","    if snp_info[\"chromosome\"] not in [\"X\", \"Y\", \"MT\"]:\n","        p = snp_info[\"allele1_freq\"]\n","        prob_aa = p ** 2\n","        prob_ab = 2 * p * (1 - p)\n","        r = np.random.rand(n)\n","        called_idx = np.where(call_mask)[0]\n","        if len(called_idx) > 0:\n","            geno = np.empty(len(called_idx), dtype=object)\n","            r_called = r[called_idx]\n","            geno[r_called < prob_aa] = ''.join(sorted(snp_info[\"allele1\"] * 2))\n","            geno[(r_called >= prob_aa) & (r_called < (prob_aa + prob_ab))] = ''.join(sorted(snp_info[\"allele1\"] + snp_info[\"allele2\"]))\n","            geno[r_called >= (prob_aa + prob_ab)] = ''.join(sorted(snp_info[\"allele2\"] * 2))\n","            genotypes[called_idx] = geno\n","        return genotypes\n","    elif snp_info[\"chromosome\"] == \"X\":\n","        p = snp_info[\"allele1_freq\"]\n","        r = np.random.rand(n)\n","        called_idx = np.where(call_mask)[0]\n","        if len(called_idx) > 0:\n","            # Process males and females separately:\n","            male_indices = [i for i in called_idx if genders[i] == \"Male\"]\n","            if male_indices:\n","                r_male = np.random.rand(len(male_indices))\n","                geno_male = np.where(r_male < p, snp_info[\"allele1\"], snp_info[\"allele2\"])\n","                for idx, val in zip(male_indices, geno_male):\n","                    genotypes[idx] = val\n","            female_indices = [i for i in called_idx if genders[i] == \"Female\"]\n","            if female_indices:\n","                r_female = np.random.rand(len(female_indices))\n","                prob_aa = p ** 2\n","                prob_ab = 2 * p * (1 - p)\n","                geno_female = np.empty(len(female_indices), dtype=object)\n","                geno_female[r_female < prob_aa] = ''.join(sorted(snp_info[\"allele1\"] * 2))\n","                geno_female[(r_female >= prob_aa) & (r_female < (prob_aa + prob_ab))] = ''.join(sorted(snp_info[\"allele1\"] + snp_info[\"allele2\"]))\n","                geno_female[r_female >= (prob_aa + prob_ab)] = ''.join(sorted(snp_info[\"allele2\"] * 2))\n","                for idx, val in zip(female_indices, geno_female):\n","                    genotypes[idx] = val\n","        return genotypes\n","    elif snp_info[\"chromosome\"] == \"Y\":\n","        r = np.random.rand(n)\n","        called_idx = np.where(call_mask)[0]\n","        for i in called_idx:\n","            if genders[i] == \"Male\":\n","                r_val = random.random()  # CPU random value\n","                genotypes[i] = snp_info[\"allele1\"] if r_val < snp_info[\"allele1_freq\"] else snp_info[\"allele2\"]\n","        return genotypes\n","    elif snp_info[\"chromosome\"] == \"MT\":\n","        r = np.random.rand(n)\n","        called_idx = np.where(call_mask)[0]\n","        for i in called_idx:\n","            r_val = random.random()\n","            genotypes[i] = snp_info[\"allele1\"] if r_val < snp_info[\"allele1_freq\"] else snp_info[\"allele2\"]\n","        return genotypes\n","\n","# Get the list of genders for all individuals.\n","genders_list = individuals_df[\"gender\"].tolist()\n","\n","# Write the SNP genotype matrix one chunk at a time.\n","chunk_size = 100000\n","print(\"Writing SNP genotypes in chunks...\")\n","with open(snp_file, \"w\", newline=\"\") as f_out:\n","    writer = csv.writer(f_out)\n","    # Write header: first column is individual_id then one column per SNP marker.\n","    header = [\"individual_id\"] + [snp[\"snp_id\"] for snp in snp_annotations]\n","    writer.writerow(header)\n","    # Process individuals in chunks\n","    for start in tqdm(range(0, NUM_INDIVIDUALS, chunk_size), desc=\"SNP Genotype Chunks\"):\n","        end = min(start + chunk_size, NUM_INDIVIDUALS)\n","        chunk_genders = genders_list[start:end]\n","        chunk_ind_ids = individuals_df[\"individual_id\"].iloc[start:end].tolist()\n","        # For each SNP marker, compute the genotype calls for this chunk.\n","        chunk_genotypes = []  # List of arrays; one per SNP.\n","        for snp in snp_annotations:\n","            check_memory(MEMORY_THRESHOLD_PERCENT)\n","            geno_chunk = compute_snp_genotype_for_chunk(snp, chunk_genders)\n","            chunk_genotypes.append(geno_chunk)\n","        # Write one row per individual in this chunk.\n","        for i in range(len(chunk_genders)):\n","            row = [chunk_ind_ids[i]] + [chunk_genotypes[j][i] for j in range(len(chunk_genotypes))]\n","            writer.writerow(row)\n","        del chunk_genotypes\n","        gc.collect()\n","print(f\"SNP genotype data saved to {snp_file}\")\n","\n","# =============================================================================\n","# Step 6: Generate Indel Definitions and Genotypes (Chunked Writing to CSV, CPU Only)\n","# =============================================================================\n","print(\"Generating Indel definitions with genomic annotations...\")\n","indel_definitions = []\n","for i in tqdm(range(NUM_INDELS), desc=\"Indel Definitions\"):\n","    indel_id = f\"INDEL_{i+1:04d}\"\n","    ref_allele = random.choice(nucleotides)\n","    alt_length = random.randint(1, 10)\n","    alt_allele = ''.join(random.choices(nucleotides, k=alt_length))\n","    frequency = random.uniform(0.05, 0.5)\n","    call_rate = round(random.uniform(0.95, 0.99), 3)\n","    chromosome = get_random_chromosome()\n","    position = random.randint(1, chr_lengths[chromosome])\n","    region_type = random.choices(region_types, weights=region_weights, k=1)[0]\n","    functional_effect = get_functional_effect(region_type)\n","    indel_definitions.append({\n","        \"indel_id\": indel_id,\n","        \"ref_allele\": ref_allele,\n","        \"alt_allele\": alt_allele,\n","        \"frequency\": round(frequency, 3),\n","        \"call_rate\": call_rate,\n","        \"length\": alt_length,\n","        \"chromosome\": chromosome,\n","        \"position\": position,\n","        \"region_type\": region_type,\n","        \"functional_effect\": functional_effect\n","    })\n","indel_def_df = pd.DataFrame(indel_definitions)\n","indel_def_df[\"chromosome\"] = indel_def_df[\"chromosome\"].astype(\"category\")\n","indel_def_df[\"region_type\"] = indel_def_df[\"region_type\"].astype(\"category\")\n","indel_def_df[\"functional_effect\"] = indel_def_df[\"functional_effect\"].astype(\"category\")\n","indel_def_df.to_csv(indel_def_file, index=False)\n","print(f\"Indel definitions saved to {indel_def_file}\")\n","del indel_definitions\n","gc.collect()\n","# Convert to list of dictionaries for later use.\n","indel_annotations = indel_def_df.to_dict('records')\n","\n","def compute_indel_genotype_for_chunk(indel_info, genders):\n","    \"\"\"Compute genotype calls for a given indel marker for a chunk of individuals.\"\"\"\n","    n = len(genders)\n","    genotypes = np.full(n, \"NA\", dtype=object)\n","    call_mask = np.random.rand(n) <= indel_info[\"call_rate\"]\n","    if indel_info[\"chromosome\"] not in [\"X\", \"Y\", \"MT\"]:\n","        p = indel_info[\"frequency\"]\n","        prob_rr = p ** 2\n","        prob_ra = 2 * p * (1 - p)\n","        r = np.random.rand(n)\n","        called_idx = np.where(call_mask)[0]\n","        if len(called_idx) > 0:\n","            geno = np.empty(len(called_idx), dtype=object)\n","            r_called = r[called_idx]\n","            geno[r_called < prob_rr] = ''.join(sorted(indel_info[\"ref_allele\"] * 2))\n","            geno[(r_called >= prob_rr) & (r_called < (prob_rr + prob_ra))] = ''.join(sorted(indel_info[\"ref_allele\"] + indel_info[\"alt_allele\"]))\n","            geno[r_called >= (prob_rr + prob_ra)] = ''.join(sorted(indel_info[\"alt_allele\"] * 2))\n","            genotypes[called_idx] = geno\n","        return genotypes\n","    elif indel_info[\"chromosome\"] == \"X\":\n","        p = indel_info[\"frequency\"]\n","        r = np.random.rand(n)\n","        called_idx = np.where(call_mask)[0]\n","        if len(called_idx) > 0:\n","            male_indices = [i for i in called_idx if genders[i] == \"Male\"]\n","            if male_indices:\n","                r_male = np.random.rand(len(male_indices))\n","                geno_male = np.where(r_male < p, indel_info[\"ref_allele\"], indel_info[\"alt_allele\"])\n","                for idx, val in zip(male_indices, geno_male):\n","                    genotypes[idx] = val\n","            female_indices = [i for i in called_idx if genders[i] == \"Female\"]\n","            if female_indices:\n","                r_female = np.random.rand(len(female_indices))\n","                prob_rr = p ** 2\n","                prob_ra = 2 * p * (1 - p)\n","                geno_female = np.empty(len(female_indices), dtype=object)\n","                geno_female[r_female < prob_rr] = ''.join(sorted(indel_info[\"ref_allele\"] * 2))\n","                geno_female[(r_female >= prob_rr) & (r_female < (prob_rr + prob_ra))] = ''.join(sorted(indel_info[\"ref_allele\"] + indel_info[\"alt_allele\"]))\n","                geno_female[r_female >= (prob_rr + prob_ra)] = ''.join(sorted(indel_info[\"alt_allele\"] * 2))\n","                for idx, val in zip(female_indices, geno_female):\n","                    genotypes[idx] = val\n","        return genotypes\n","    elif indel_info[\"chromosome\"] == \"Y\":\n","        r = np.random.rand(n)\n","        called_idx = np.where(call_mask)[0]\n","        for i in called_idx:\n","            if genders[i] == \"Male\":\n","                r_val = random.random()\n","                genotypes[i] = indel_info[\"ref_allele\"] if r_val < indel_info[\"frequency\"] else indel_info[\"alt_allele\"]\n","        return genotypes\n","    elif indel_info[\"chromosome\"] == \"MT\":\n","        r = np.random.rand(n)\n","        called_idx = np.where(call_mask)[0]\n","        for i in called_idx:\n","            r_val = random.random()\n","            genotypes[i] = indel_info[\"ref_allele\"] if r_val < indel_info[\"frequency\"] else indel_info[\"alt_allele\"]\n","        return genotypes\n","\n","print(\"Writing indel genotypes in chunks...\")\n","with open(indel_file, \"w\", newline=\"\") as f_out:\n","    writer = csv.writer(f_out)\n","    header = [\"individual_id\"] + [indel[\"indel_id\"] for indel in indel_annotations]\n","    writer.writerow(header)\n","    for start in tqdm(range(0, NUM_INDIVIDUALS, chunk_size), desc=\"Indel Genotype Chunks\"):\n","        end = min(start + chunk_size, NUM_INDIVIDUALS)\n","        chunk_genders = genders_list[start:end]\n","        chunk_ind_ids = individuals_df[\"individual_id\"].iloc[start:end].tolist()\n","        chunk_genotypes = []\n","        for indel in indel_annotations:\n","            check_memory(MEMORY_THRESHOLD_PERCENT)\n","            geno_chunk = compute_indel_genotype_for_chunk(indel, chunk_genders)\n","            chunk_genotypes.append(geno_chunk)\n","        for i in range(len(chunk_genders)):\n","            row = [chunk_ind_ids[i]] + [chunk_genotypes[j][i] for j in range(len(chunk_genotypes))]\n","            writer.writerow(row)\n","        del chunk_genotypes\n","        gc.collect()\n","print(f\"Indel genotype data saved to {indel_file}\")\n","\n","# =============================================================================\n","# Step 7: Generate Structural Variants Data (with size bounds check)\n","# =============================================================================\n","print(\"Generating structural variants data...\")\n","sv_data = []\n","variant_types_list = [\"Deletion\", \"Duplication\", \"Inversion\", \"Translocation\"]\n","variant_counter = 1\n","for ind in tqdm(individuals_df['individual_id'], desc=\"Structural Variants\"):\n","    check_memory(MEMORY_THRESHOLD_PERCENT)\n","    if random.random() < SV_PROBABILITY:\n","        num_variants = random.randint(1, 3)\n","        for _ in range(num_variants):\n","            sv_id = f\"SV_{variant_counter:06d}\"\n","            variant_counter += 1\n","            sv_type = random.choice(variant_types_list)\n","            chromosome = get_random_chromosome()\n","            max_chr_length = chr_lengths[chromosome]\n","            # Compute maximum possible size for this chromosome.\n","            max_possible_size = max_chr_length - 1  # leave at least one base for start_pos\n","            # If the maximum possible size is less than our desired minimum variant size, skip this variant.\n","            if max_possible_size < 1000:\n","                continue\n","            # Choose size between 1,000 and the smaller of 1,000,000 or max_possible_size.\n","            size = random.randint(1000, min(1_000_000, max_possible_size))\n","            start_pos = random.randint(1, max_chr_length - size)\n","            end_pos = start_pos + size\n","            quality = round(random.uniform(20, 60), 1)\n","            sv_data.append({\n","                \"individual_id\": ind,\n","                \"sv_id\": sv_id,\n","                \"variant_type\": sv_type,\n","                \"chromosome\": chromosome,\n","                \"start_pos\": start_pos,\n","                \"end_pos\": end_pos,\n","                \"size_bp\": size,\n","                \"quality\": quality\n","            })\n","sv_df = pd.DataFrame(sv_data)\n","sv_df.to_csv(sv_file, index=False)\n","print(f\"Structural variants data saved to {sv_file}\")\n","\n","\n","# =============================================================================\n","# Step 8: Generate Health and Phenotype Data (Vectorized)\n","# =============================================================================\n","print(\"Generating health and phenotype data (vectorized)...\")\n","n = len(individuals_df)\n","health_data = {\n","    \"individual_id\": individuals_df[\"individual_id\"],\n","    \"height_cm\": np.round(np.random.normal(170, 10, n), 1),\n","    \"weight_kg\": np.round(np.random.normal(70, 15, n), 1)\n","}\n","health_data[\"bmi\"] = np.round(health_data[\"weight_kg\"] / ((health_data[\"height_cm\"] / 100) ** 2), 1)\n","health_data[\"eye_color\"] = np.random.choice([\"Brown\", \"Blue\", \"Green\", \"Hazel\", \"Gray\"], n)\n","health_data[\"blood_type\"] = np.random.choice([\"A\", \"B\", \"AB\", \"O\"], n)\n","health_data[\"diabetes\"] = np.random.choice([\"Yes\", \"No\"], n, p=[0.1, 0.9])\n","health_data[\"hypertension\"] = np.random.choice([\"Yes\", \"No\"], n, p=[0.15, 0.85])\n","pd.DataFrame(health_data).to_csv(health_file, index=False)\n","print(f\"Health and phenotype data saved to {health_file}\")\n","del health_data\n","gc.collect()\n","\n","# =============================================================================\n","# Step 9: Generate Lifestyle Data (Vectorized)\n","# =============================================================================\n","print(\"Generating lifestyle data (vectorized)...\")\n","occupations = [\n","    \"Accountant\", \"Actor\", \"Actuary\", \"Administrative Assistant\", \"Advertising Manager\",\n","    \"Aerospace Engineer\", \"Agricultural Scientist\", \"Air Traffic Controller\", \"Architect\",\n","    \"Artist\", \"Astronomer\", \"Attorney\", \"Biologist\", \"Biomedical Engineer\", \"Business Analyst\",\n","    \"Carpenter\", \"Chef\", \"Chemical Engineer\", \"Civil Engineer\", \"Clerk\", \"Computer Programmer\",\n","    \"Data Scientist\", \"Dentist\", \"Doctor\", \"Economist\", \"Editor\", \"Electrical Engineer\",\n","    \"Elementary School Teacher\", \"Engineer\", \"Environmental Scientist\", \"Farmer\",\n","    \"Financial Analyst\", \"Firefighter\", \"Graphic Designer\", \"Healthcare Administrator\",\n","    \"Historian\", \"Human Resources Manager\", \"Industrial Engineer\", \"Insurance Agent\",\n","    \"Interior Designer\", \"Investment Banker\", \"Journalist\", \"Lawyer\", \"Librarian\",\n","    \"Logistician\", \"Machinist\", \"Marketing Manager\", \"Mechanical Engineer\", \"Meteorologist\",\n","    \"Microbiologist\", \"Musician\", \"Nurse\", \"Occupational Therapist\", \"Operations Manager\",\n","    \"Optometrist\", \"Pharmacist\", \"Photographer\", \"Physicist\", \"Physician\", \"Plumber\",\n","    \"Police Officer\", \"Professor\", \"Project Manager\", \"Psychologist\", \"Public Relations Specialist\",\n","    \"Real Estate Agent\", \"Research Scientist\", \"Sales Manager\", \"Software Developer\",\n","    \"Statistician\", \"Surgeon\", \"Teacher\", \"Technical Writer\", \"Translator\", \"Urban Planner\",\n","    \"Veterinarian\", \"Web Developer\", \"Writer\", \"Chief Executive Officer\", \"Chief Financial Officer\",\n","    \"Consultant\", \"Executive Assistant\", \"Social Worker\", \"Event Planner\", \"Quality Assurance Analyst\",\n","    \"Supply Chain Manager\", \"Systems Analyst\", \"UX Designer\", \"Customer Service Representative\",\n","    \"Environmental Engineer\", \"Biochemist\", \"Geneticist\", \"Biomedical Researcher\", \"Forensic Scientist\"\n","]\n","lifestyle_data = {\n","    \"individual_id\": individuals_df[\"individual_id\"],\n","    \"smoker\": np.random.choice([\"Yes\", \"No\"], n, p=[0.3, 0.7]),\n","    \"alcohol_consumption\": np.random.choice([\"None\", \"Occasional\", \"Regular\", \"Heavy\"], n, p=[0.2, 0.5, 0.2, 0.1]),\n","    \"exercise\": np.random.choice([\"Sedentary\", \"Moderate\", \"Active\"], n, p=[0.4, 0.4, 0.2]),\n","    \"occupation\": np.random.choice(occupations, n)\n","}\n","pd.DataFrame(lifestyle_data).to_csv(lifestyle_file, index=False)\n","print(f\"Lifestyle data saved to {lifestyle_file}\")\n","del lifestyle_data\n","gc.collect()\n","\n","# =============================================================================\n","# Step 10: Simple UI for Output Summary using Tkinter\n","# =============================================================================\n","def show_summary_ui(file_list):\n","    root = tk.Tk()\n","    root.title(\"Data Generation Summary\")\n","    root.geometry(\"500x300\")\n","\n","    frame = ttk.Frame(root, padding=20)\n","    frame.pack(expand=True, fill=\"both\")\n","\n","    ttk.Label(frame, text=\"Data Generation Completed!\", font=(\"Arial\", 16, \"bold\")).pack(pady=10)\n","\n","    summary_text = \"\"\n","    for fname in file_list:\n","        try:\n","            df = pd.read_csv(fname)\n","            rows = len(df)\n","        except Exception as e:\n","            rows = f\"Error: {e}\"\n","        summary_text += f\"{os.path.basename(fname)}: {rows} rows\\n\"\n","\n","    txt = tk.Text(frame, wrap=\"word\", font=(\"Consolas\", 10))\n","    txt.insert(\"end\", summary_text)\n","    txt.config(state=\"disabled\")\n","    txt.pack(expand=True, fill=\"both\")\n","\n","    ttk.Button(frame, text=\"Close\", command=root.destroy).pack(pady=10)\n","    root.mainloop()\n","\n","files_generated = [individuals_file, relationships_file, marriages_file,\n","                   snp_def_file, snp_file, indel_def_file, indel_file,\n","                   sv_file, health_file, lifestyle_file]\n","\n","print(\"All stages completed. Launching output summary UI...\")\n","show_summary_ui(files_generated)\n"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO2aCFeOy0LP2uR1QNhk2Cd"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}